[2022.09.28] 베이스라인 모델 (SVC-Bagging)

스케일링 : StandardScaler

카테고리형 변수 OneHotEncoder(sparse=False)

train - validation set으로 나눠 train으로 학습 후 validation으로 검증

모델 성능 측정

accuracy_score

precision

recall

f1 score : 대회 성능 평가 지표

auc score

-> save_data 함수를 통해 변수별 중요도표 저장 (in score folder)

<StandardScaler 사용>

train score

accuracy : 0.9455244596567154, precision : 0.20784313725490197, recall : 0.00016924742376680897, f1 score : 0.00033821943421632

valid score

accuracy : 0.9453666081977908, precision : 0.2602739726027397, recall : 0.0002419858119897602, f1 score : 0.0004835220766000764

valid score에서 precision과 recall, f1 score 가 떨어졌지만 크게 떨어지지않은 것 같습니다.


data : train_prepared.csv, target_prepared.csv

model : svc_model.pkl


간단한 회의 의견

타깃 불균형
흠.. 저도 타깃불균형 해결하는 방법을 찾아봤는데
샘플링하는 부분에서 크게 두가지로 나뉘더라구요?? 오버랑 언더.. 느낌 같은데.. 요즘 모델 중에서
두개를 동시에 해주는 모델이 나왔다고 해서 그중에서 하나 사용해볼 생각입니다! 
아마 smote + tomek? 같은 모델 사용해서 해볼 생각입니다!

베이스라인 모델 개선할 점
데이터적인 측면: 
그래서 베이스라인 라인 모델 돌리기 전에 샘플링을 먼저 한 후에 진행해보는게 좋을 것 같습니다!
왜냐하면 아무래도 불균형이 있다보니 100개의 데이터 중에서 5개만 1이고 나머지가 0이면... 전부 0으로
예측을 해도 정확도가 95% 가 나오는 거니까.. 먼저 샘플링 한후에 다시 돌려보면 어떨까 생각해보았습니다..!
랜덤포레스트 : 
흠.. 오버피팅이 나왔으니.. 한번 파라미터를 조정해서 min_samples_split, min_samples_leaf 조정하고
max_depth 조정해서 과적합 방지하면 어떨까.. 생각해보았습니다..! 
흠 잘 모르지만.. min_samples_split 랑 max_depth는.. 좀 늘려보고.. min_samples_leaf도 조금 늘려보는 느낌..
SVC : 
흠.. 이거는 아무래도 선을 그어서 반으로 나누는거다 보니 타깃이 불균형해서 그냥 성능이 좋게나온게 
아닌가 생각해보았습니다.. 네.. 그리고 한번 모델 학습하는데 시간이 좀 오래걸리다보니까 파라미터 튜닝을
 하려면.. 마음을 굳게 먹어야할거 같습니다.. 그래서 한번 타깃 불균형 문제 해결한 후에 다시 해보는걸로..
( + 오차행렬 결과 구글드라이브에 이미지 폴더에 올려두었습니다!) 

MLP.. : 는 잘 모르지만.. 전에 했던 코드로 돌리고 있는데 어딘가에서 막혀서.. 해결중입니다..  

외부데이터
음.. 우선 굳이 넣는다면 코스피와.. 흠 금리..? 인데 아직 그걸 넣는다고해서 모델 성능이 좋아진다는 확신은
없으니.. 시간이 남거나.. 모델 성능을 높일 방법이 정 없다면 나중에 시도해보는 것도 나쁘지 않을 것 같습니다.

피처엔지니어링
흠... 피처엔지니어링은.. 스케일링이랑 원핫인코딩은 했으니까.. 앞으로 해볼 것을 생각해보면.. 
오버피팅이 발생하니까 조금 피처 중요도 보고 피처를 좀 없애보는 느낌으로 하면 어떨까 합니다!
랜덤포레스트나 svm 아니면 xgboost 써서 feature_importance 확인하고 한번 필요없는거 없애고 돌려보죠!

앞으로 할일
흠.. 우선 불균형문제부터 해결 -> 베이스라인 모델 개선 + 피처엔지니어링 -> 외부데이터
의 우선순위를 가지고 하면 어떨까... 하네요 한번 읽어보시고 이해안되시면.. 카톡으로 물어봐주세요!
